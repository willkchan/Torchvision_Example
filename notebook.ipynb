{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import time\n",
    "# plt.style.use('dark_background')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "# print(torch.cuda.is_available())\n",
    "#\n",
    "# print(torch.cuda.device_count())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# download training data from domain\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root='data/',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data/',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
      "shape of y:  torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size= 64\n",
    "\n",
    "# create data loaders; used to make our datasets iterable of batch size\n",
    "train_dataloader = DataLoader(training_data, batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print('Shape of X [N, C, H, W]:', X.shape)\n",
    "    print('shape of y: ', y.shape, y.dtype)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [
    {
     "data": {
      "text/plain": "['T-shirt/top',\n 'Trouser',\n 'Pullover',\n 'Dress',\n 'Coat',\n 'Sandal',\n 'Shirt',\n 'Sneaker',\n 'Bag',\n 'Ankle boot']"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.classes\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "data": {
      "text/plain": "(60000, 10000)"
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data), len(test_data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 576x576 with 9 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_map = training_data.classes\n",
    "\n",
    "figure = plt.figure(figsize=(8,8))\n",
    "cols, rows = 3,3\n",
    "\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    # used to show entire batch sample of images\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    # this is just for aesthetics\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    # this shows the image\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "print(sys.getrecursionlimit())\n",
    "sys.setrecursionlimit(100000)\n",
    "print(sys.getrecursionlimit())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# creat models\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "# print(\"Using {} device\".format(device))\n",
    "# define model\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "# optmization and loss fn\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "# make functions for running nn on our train and test\n",
    "# in the loop, teh model makes predictions from the training data (and each iteration will\n",
    "# be a batch of data), after predictions we backpropagate the prediction erros to adjust\n",
    "# the parameters\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X,y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # computer pred error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # bp\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f} [{current:>5d}/{size:>5d}]')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "# can also check the models performacne against the dataset to ensure it is learning\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= size\n",
    "        correct /= size\n",
    "        print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.253779 [    0/60000]\n",
      "loss: 0.435515 [ 6400/60000]\n",
      "loss: 0.267931 [12800/60000]\n",
      "loss: 0.473817 [19200/60000]\n",
      "loss: 0.358384 [25600/60000]\n",
      "loss: 0.398439 [32000/60000]\n",
      "loss: 0.402119 [38400/60000]\n",
      "loss: 0.562229 [44800/60000]\n",
      "loss: 0.541890 [51200/60000]\n",
      "loss: 0.377536 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.006840 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.252844 [    0/60000]\n",
      "loss: 0.434261 [ 6400/60000]\n",
      "loss: 0.267366 [12800/60000]\n",
      "loss: 0.472472 [19200/60000]\n",
      "loss: 0.357274 [25600/60000]\n",
      "loss: 0.397299 [32000/60000]\n",
      "loss: 0.400904 [38400/60000]\n",
      "loss: 0.561010 [44800/60000]\n",
      "loss: 0.540371 [51200/60000]\n",
      "loss: 0.376795 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.006827 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.251914 [    0/60000]\n",
      "loss: 0.433012 [ 6400/60000]\n",
      "loss: 0.266777 [12800/60000]\n",
      "loss: 0.471195 [19200/60000]\n",
      "loss: 0.356174 [25600/60000]\n",
      "loss: 0.396190 [32000/60000]\n",
      "loss: 0.399748 [38400/60000]\n",
      "loss: 0.559759 [44800/60000]\n",
      "loss: 0.538885 [51200/60000]\n",
      "loss: 0.376037 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.4%, Avg loss: 0.006815 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.251018 [    0/60000]\n",
      "loss: 0.431815 [ 6400/60000]\n",
      "loss: 0.266213 [12800/60000]\n",
      "loss: 0.469898 [19200/60000]\n",
      "loss: 0.355078 [25600/60000]\n",
      "loss: 0.395121 [32000/60000]\n",
      "loss: 0.398610 [38400/60000]\n",
      "loss: 0.558622 [44800/60000]\n",
      "loss: 0.537463 [51200/60000]\n",
      "loss: 0.375265 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.006803 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.250193 [    0/60000]\n",
      "loss: 0.430638 [ 6400/60000]\n",
      "loss: 0.265640 [12800/60000]\n",
      "loss: 0.468498 [19200/60000]\n",
      "loss: 0.354111 [25600/60000]\n",
      "loss: 0.393967 [32000/60000]\n",
      "loss: 0.397448 [38400/60000]\n",
      "loss: 0.557466 [44800/60000]\n",
      "loss: 0.536113 [51200/60000]\n",
      "loss: 0.374538 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.006791 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.249397 [    0/60000]\n",
      "loss: 0.429449 [ 6400/60000]\n",
      "loss: 0.265034 [12800/60000]\n",
      "loss: 0.467165 [19200/60000]\n",
      "loss: 0.353092 [25600/60000]\n",
      "loss: 0.392902 [32000/60000]\n",
      "loss: 0.396287 [38400/60000]\n",
      "loss: 0.556351 [44800/60000]\n",
      "loss: 0.534792 [51200/60000]\n",
      "loss: 0.373850 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.006779 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.248603 [    0/60000]\n",
      "loss: 0.428315 [ 6400/60000]\n",
      "loss: 0.264447 [12800/60000]\n",
      "loss: 0.465784 [19200/60000]\n",
      "loss: 0.352073 [25600/60000]\n",
      "loss: 0.391854 [32000/60000]\n",
      "loss: 0.395140 [38400/60000]\n",
      "loss: 0.555288 [44800/60000]\n",
      "loss: 0.533420 [51200/60000]\n",
      "loss: 0.373132 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.5%, Avg loss: 0.006767 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.247873 [    0/60000]\n",
      "loss: 0.427250 [ 6400/60000]\n",
      "loss: 0.263918 [12800/60000]\n",
      "loss: 0.464441 [19200/60000]\n",
      "loss: 0.351184 [25600/60000]\n",
      "loss: 0.390777 [32000/60000]\n",
      "loss: 0.394008 [38400/60000]\n",
      "loss: 0.554155 [44800/60000]\n",
      "loss: 0.532046 [51200/60000]\n",
      "loss: 0.372430 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.006756 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.247144 [    0/60000]\n",
      "loss: 0.426148 [ 6400/60000]\n",
      "loss: 0.263323 [12800/60000]\n",
      "loss: 0.463152 [19200/60000]\n",
      "loss: 0.350265 [25600/60000]\n",
      "loss: 0.389750 [32000/60000]\n",
      "loss: 0.392924 [38400/60000]\n",
      "loss: 0.553011 [44800/60000]\n",
      "loss: 0.530652 [51200/60000]\n",
      "loss: 0.371754 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.006744 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.246481 [    0/60000]\n",
      "loss: 0.425036 [ 6400/60000]\n",
      "loss: 0.262779 [12800/60000]\n",
      "loss: 0.461861 [19200/60000]\n",
      "loss: 0.349341 [25600/60000]\n",
      "loss: 0.388773 [32000/60000]\n",
      "loss: 0.391911 [38400/60000]\n",
      "loss: 0.551863 [44800/60000]\n",
      "loss: 0.529271 [51200/60000]\n",
      "loss: 0.371108 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.6%, Avg loss: 0.006733 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.245774 [    0/60000]\n",
      "loss: 0.423856 [ 6400/60000]\n",
      "loss: 0.262216 [12800/60000]\n",
      "loss: 0.460654 [19200/60000]\n",
      "loss: 0.348335 [25600/60000]\n",
      "loss: 0.387801 [32000/60000]\n",
      "loss: 0.390898 [38400/60000]\n",
      "loss: 0.550737 [44800/60000]\n",
      "loss: 0.527922 [51200/60000]\n",
      "loss: 0.370420 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.006722 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.245021 [    0/60000]\n",
      "loss: 0.422657 [ 6400/60000]\n",
      "loss: 0.261611 [12800/60000]\n",
      "loss: 0.459434 [19200/60000]\n",
      "loss: 0.347434 [25600/60000]\n",
      "loss: 0.386806 [32000/60000]\n",
      "loss: 0.389916 [38400/60000]\n",
      "loss: 0.549618 [44800/60000]\n",
      "loss: 0.526547 [51200/60000]\n",
      "loss: 0.369729 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.006710 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.244319 [    0/60000]\n",
      "loss: 0.421524 [ 6400/60000]\n",
      "loss: 0.261045 [12800/60000]\n",
      "loss: 0.458190 [19200/60000]\n",
      "loss: 0.346509 [25600/60000]\n",
      "loss: 0.385870 [32000/60000]\n",
      "loss: 0.388891 [38400/60000]\n",
      "loss: 0.548548 [44800/60000]\n",
      "loss: 0.525179 [51200/60000]\n",
      "loss: 0.369135 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.7%, Avg loss: 0.006699 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.243675 [    0/60000]\n",
      "loss: 0.420394 [ 6400/60000]\n",
      "loss: 0.260487 [12800/60000]\n",
      "loss: 0.456947 [19200/60000]\n",
      "loss: 0.345577 [25600/60000]\n",
      "loss: 0.384945 [32000/60000]\n",
      "loss: 0.387910 [38400/60000]\n",
      "loss: 0.547473 [44800/60000]\n",
      "loss: 0.523847 [51200/60000]\n",
      "loss: 0.368517 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.006689 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.243008 [    0/60000]\n",
      "loss: 0.419243 [ 6400/60000]\n",
      "loss: 0.259940 [12800/60000]\n",
      "loss: 0.455739 [19200/60000]\n",
      "loss: 0.344655 [25600/60000]\n",
      "loss: 0.384021 [32000/60000]\n",
      "loss: 0.386899 [38400/60000]\n",
      "loss: 0.546446 [44800/60000]\n",
      "loss: 0.522440 [51200/60000]\n",
      "loss: 0.367872 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.006678 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 0.242357 [    0/60000]\n",
      "loss: 0.418206 [ 6400/60000]\n",
      "loss: 0.259423 [12800/60000]\n",
      "loss: 0.454511 [19200/60000]\n",
      "loss: 0.343746 [25600/60000]\n",
      "loss: 0.383079 [32000/60000]\n",
      "loss: 0.385883 [38400/60000]\n",
      "loss: 0.545406 [44800/60000]\n",
      "loss: 0.521130 [51200/60000]\n",
      "loss: 0.367196 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.006667 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.241736 [    0/60000]\n",
      "loss: 0.417142 [ 6400/60000]\n",
      "loss: 0.258956 [12800/60000]\n",
      "loss: 0.453332 [19200/60000]\n",
      "loss: 0.342855 [25600/60000]\n",
      "loss: 0.382131 [32000/60000]\n",
      "loss: 0.384836 [38400/60000]\n",
      "loss: 0.544349 [44800/60000]\n",
      "loss: 0.519742 [51200/60000]\n",
      "loss: 0.366551 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.006657 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 0.241128 [    0/60000]\n",
      "loss: 0.416072 [ 6400/60000]\n",
      "loss: 0.258431 [12800/60000]\n",
      "loss: 0.452170 [19200/60000]\n",
      "loss: 0.341950 [25600/60000]\n",
      "loss: 0.381187 [32000/60000]\n",
      "loss: 0.383820 [38400/60000]\n",
      "loss: 0.543321 [44800/60000]\n",
      "loss: 0.518492 [51200/60000]\n",
      "loss: 0.365910 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.8%, Avg loss: 0.006646 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 0.240565 [    0/60000]\n",
      "loss: 0.415078 [ 6400/60000]\n",
      "loss: 0.257908 [12800/60000]\n",
      "loss: 0.451048 [19200/60000]\n",
      "loss: 0.341052 [25600/60000]\n",
      "loss: 0.380246 [32000/60000]\n",
      "loss: 0.382775 [38400/60000]\n",
      "loss: 0.542300 [44800/60000]\n",
      "loss: 0.517244 [51200/60000]\n",
      "loss: 0.365326 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.006636 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 0.240027 [    0/60000]\n",
      "loss: 0.414081 [ 6400/60000]\n",
      "loss: 0.257446 [12800/60000]\n",
      "loss: 0.449947 [19200/60000]\n",
      "loss: 0.340108 [25600/60000]\n",
      "loss: 0.379326 [32000/60000]\n",
      "loss: 0.381733 [38400/60000]\n",
      "loss: 0.541253 [44800/60000]\n",
      "loss: 0.516016 [51200/60000]\n",
      "loss: 0.364733 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 84.9%, Avg loss: 0.006626 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 0.239474 [    0/60000]\n",
      "loss: 0.413046 [ 6400/60000]\n",
      "loss: 0.257018 [12800/60000]\n",
      "loss: 0.448820 [19200/60000]\n",
      "loss: 0.339238 [25600/60000]\n",
      "loss: 0.378442 [32000/60000]\n",
      "loss: 0.380739 [38400/60000]\n",
      "loss: 0.540274 [44800/60000]\n",
      "loss: 0.514861 [51200/60000]\n",
      "loss: 0.364149 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.006616 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 0.238988 [    0/60000]\n",
      "loss: 0.412096 [ 6400/60000]\n",
      "loss: 0.256505 [12800/60000]\n",
      "loss: 0.447695 [19200/60000]\n",
      "loss: 0.338401 [25600/60000]\n",
      "loss: 0.377513 [32000/60000]\n",
      "loss: 0.379762 [38400/60000]\n",
      "loss: 0.539299 [44800/60000]\n",
      "loss: 0.513678 [51200/60000]\n",
      "loss: 0.363580 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.006605 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 0.238530 [    0/60000]\n",
      "loss: 0.411131 [ 6400/60000]\n",
      "loss: 0.256029 [12800/60000]\n",
      "loss: 0.446562 [19200/60000]\n",
      "loss: 0.337539 [25600/60000]\n",
      "loss: 0.376597 [32000/60000]\n",
      "loss: 0.378621 [38400/60000]\n",
      "loss: 0.538275 [44800/60000]\n",
      "loss: 0.512474 [51200/60000]\n",
      "loss: 0.363040 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.006595 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 0.238028 [    0/60000]\n",
      "loss: 0.410183 [ 6400/60000]\n",
      "loss: 0.255530 [12800/60000]\n",
      "loss: 0.445428 [19200/60000]\n",
      "loss: 0.336670 [25600/60000]\n",
      "loss: 0.375785 [32000/60000]\n",
      "loss: 0.377647 [38400/60000]\n",
      "loss: 0.537231 [44800/60000]\n",
      "loss: 0.511302 [51200/60000]\n",
      "loss: 0.362484 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.006585 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 0.237480 [    0/60000]\n",
      "loss: 0.409177 [ 6400/60000]\n",
      "loss: 0.255104 [12800/60000]\n",
      "loss: 0.444225 [19200/60000]\n",
      "loss: 0.335881 [25600/60000]\n",
      "loss: 0.374980 [32000/60000]\n",
      "loss: 0.376699 [38400/60000]\n",
      "loss: 0.536204 [44800/60000]\n",
      "loss: 0.510146 [51200/60000]\n",
      "loss: 0.362015 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.0%, Avg loss: 0.006575 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 0.236958 [    0/60000]\n",
      "loss: 0.408255 [ 6400/60000]\n",
      "loss: 0.254636 [12800/60000]\n",
      "loss: 0.443027 [19200/60000]\n",
      "loss: 0.335099 [25600/60000]\n",
      "loss: 0.374184 [32000/60000]\n",
      "loss: 0.375770 [38400/60000]\n",
      "loss: 0.535335 [44800/60000]\n",
      "loss: 0.509006 [51200/60000]\n",
      "loss: 0.361552 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.006566 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 0.236437 [    0/60000]\n",
      "loss: 0.407284 [ 6400/60000]\n",
      "loss: 0.254232 [12800/60000]\n",
      "loss: 0.441872 [19200/60000]\n",
      "loss: 0.334404 [25600/60000]\n",
      "loss: 0.373423 [32000/60000]\n",
      "loss: 0.374812 [38400/60000]\n",
      "loss: 0.534322 [44800/60000]\n",
      "loss: 0.507933 [51200/60000]\n",
      "loss: 0.361052 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.006556 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 0.235949 [    0/60000]\n",
      "loss: 0.406378 [ 6400/60000]\n",
      "loss: 0.253822 [12800/60000]\n",
      "loss: 0.440800 [19200/60000]\n",
      "loss: 0.333680 [25600/60000]\n",
      "loss: 0.372642 [32000/60000]\n",
      "loss: 0.373758 [38400/60000]\n",
      "loss: 0.533287 [44800/60000]\n",
      "loss: 0.506811 [51200/60000]\n",
      "loss: 0.360670 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.1%, Avg loss: 0.006546 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 0.235483 [    0/60000]\n",
      "loss: 0.405364 [ 6400/60000]\n",
      "loss: 0.253355 [12800/60000]\n",
      "loss: 0.439688 [19200/60000]\n",
      "loss: 0.332891 [25600/60000]\n",
      "loss: 0.371849 [32000/60000]\n",
      "loss: 0.372671 [38400/60000]\n",
      "loss: 0.532250 [44800/60000]\n",
      "loss: 0.505701 [51200/60000]\n",
      "loss: 0.360284 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.006537 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 0.234979 [    0/60000]\n",
      "loss: 0.404317 [ 6400/60000]\n",
      "loss: 0.253002 [12800/60000]\n",
      "loss: 0.438621 [19200/60000]\n",
      "loss: 0.332130 [25600/60000]\n",
      "loss: 0.371105 [32000/60000]\n",
      "loss: 0.371650 [38400/60000]\n",
      "loss: 0.531192 [44800/60000]\n",
      "loss: 0.504549 [51200/60000]\n",
      "loss: 0.359838 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.006528 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 0.234480 [    0/60000]\n",
      "loss: 0.403292 [ 6400/60000]\n",
      "loss: 0.252613 [12800/60000]\n",
      "loss: 0.437556 [19200/60000]\n",
      "loss: 0.331402 [25600/60000]\n",
      "loss: 0.370304 [32000/60000]\n",
      "loss: 0.370627 [38400/60000]\n",
      "loss: 0.530093 [44800/60000]\n",
      "loss: 0.503424 [51200/60000]\n",
      "loss: 0.359463 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.006519 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 0.233995 [    0/60000]\n",
      "loss: 0.402291 [ 6400/60000]\n",
      "loss: 0.252259 [12800/60000]\n",
      "loss: 0.436496 [19200/60000]\n",
      "loss: 0.330663 [25600/60000]\n",
      "loss: 0.369499 [32000/60000]\n",
      "loss: 0.369638 [38400/60000]\n",
      "loss: 0.528989 [44800/60000]\n",
      "loss: 0.502333 [51200/60000]\n",
      "loss: 0.359021 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.006509 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 0.233477 [    0/60000]\n",
      "loss: 0.401312 [ 6400/60000]\n",
      "loss: 0.251837 [12800/60000]\n",
      "loss: 0.435493 [19200/60000]\n",
      "loss: 0.329915 [25600/60000]\n",
      "loss: 0.368716 [32000/60000]\n",
      "loss: 0.368764 [38400/60000]\n",
      "loss: 0.527907 [44800/60000]\n",
      "loss: 0.501196 [51200/60000]\n",
      "loss: 0.358571 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.006501 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: 0.232993 [    0/60000]\n",
      "loss: 0.400288 [ 6400/60000]\n",
      "loss: 0.251434 [12800/60000]\n",
      "loss: 0.434521 [19200/60000]\n",
      "loss: 0.329224 [25600/60000]\n",
      "loss: 0.367988 [32000/60000]\n",
      "loss: 0.367887 [38400/60000]\n",
      "loss: 0.526848 [44800/60000]\n",
      "loss: 0.500031 [51200/60000]\n",
      "loss: 0.358116 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.2%, Avg loss: 0.006492 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: 0.232533 [    0/60000]\n",
      "loss: 0.399363 [ 6400/60000]\n",
      "loss: 0.251008 [12800/60000]\n",
      "loss: 0.433577 [19200/60000]\n",
      "loss: 0.328513 [25600/60000]\n",
      "loss: 0.367276 [32000/60000]\n",
      "loss: 0.367024 [38400/60000]\n",
      "loss: 0.525813 [44800/60000]\n",
      "loss: 0.498930 [51200/60000]\n",
      "loss: 0.357613 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.006483 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: 0.232138 [    0/60000]\n",
      "loss: 0.398449 [ 6400/60000]\n",
      "loss: 0.250582 [12800/60000]\n",
      "loss: 0.432644 [19200/60000]\n",
      "loss: 0.327855 [25600/60000]\n",
      "loss: 0.366571 [32000/60000]\n",
      "loss: 0.366233 [38400/60000]\n",
      "loss: 0.524785 [44800/60000]\n",
      "loss: 0.497876 [51200/60000]\n",
      "loss: 0.357130 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.006475 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: 0.231734 [    0/60000]\n",
      "loss: 0.397494 [ 6400/60000]\n",
      "loss: 0.250188 [12800/60000]\n",
      "loss: 0.431668 [19200/60000]\n",
      "loss: 0.327212 [25600/60000]\n",
      "loss: 0.365919 [32000/60000]\n",
      "loss: 0.365420 [38400/60000]\n",
      "loss: 0.523742 [44800/60000]\n",
      "loss: 0.496818 [51200/60000]\n",
      "loss: 0.356702 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.006466 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: 0.231302 [    0/60000]\n",
      "loss: 0.396558 [ 6400/60000]\n",
      "loss: 0.249801 [12800/60000]\n",
      "loss: 0.430749 [19200/60000]\n",
      "loss: 0.326498 [25600/60000]\n",
      "loss: 0.365208 [32000/60000]\n",
      "loss: 0.364641 [38400/60000]\n",
      "loss: 0.522769 [44800/60000]\n",
      "loss: 0.495723 [51200/60000]\n",
      "loss: 0.356345 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.006457 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: 0.230903 [    0/60000]\n",
      "loss: 0.395629 [ 6400/60000]\n",
      "loss: 0.249447 [12800/60000]\n",
      "loss: 0.429851 [19200/60000]\n",
      "loss: 0.325821 [25600/60000]\n",
      "loss: 0.364512 [32000/60000]\n",
      "loss: 0.363832 [38400/60000]\n",
      "loss: 0.521768 [44800/60000]\n",
      "loss: 0.494682 [51200/60000]\n",
      "loss: 0.355947 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.3%, Avg loss: 0.006449 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: 0.230503 [    0/60000]\n",
      "loss: 0.394707 [ 6400/60000]\n",
      "loss: 0.249032 [12800/60000]\n",
      "loss: 0.428908 [19200/60000]\n",
      "loss: 0.325130 [25600/60000]\n",
      "loss: 0.363825 [32000/60000]\n",
      "loss: 0.362983 [38400/60000]\n",
      "loss: 0.520710 [44800/60000]\n",
      "loss: 0.493645 [51200/60000]\n",
      "loss: 0.355564 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.006440 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: 0.230057 [    0/60000]\n",
      "loss: 0.393803 [ 6400/60000]\n",
      "loss: 0.248669 [12800/60000]\n",
      "loss: 0.427987 [19200/60000]\n",
      "loss: 0.324452 [25600/60000]\n",
      "loss: 0.363146 [32000/60000]\n",
      "loss: 0.362158 [38400/60000]\n",
      "loss: 0.519644 [44800/60000]\n",
      "loss: 0.492605 [51200/60000]\n",
      "loss: 0.355188 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.006432 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: 0.229623 [    0/60000]\n",
      "loss: 0.392913 [ 6400/60000]\n",
      "loss: 0.248259 [12800/60000]\n",
      "loss: 0.427043 [19200/60000]\n",
      "loss: 0.323816 [25600/60000]\n",
      "loss: 0.362497 [32000/60000]\n",
      "loss: 0.361406 [38400/60000]\n",
      "loss: 0.518674 [44800/60000]\n",
      "loss: 0.491573 [51200/60000]\n",
      "loss: 0.354855 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.006424 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: 0.229190 [    0/60000]\n",
      "loss: 0.391991 [ 6400/60000]\n",
      "loss: 0.247905 [12800/60000]\n",
      "loss: 0.426151 [19200/60000]\n",
      "loss: 0.323226 [25600/60000]\n",
      "loss: 0.361852 [32000/60000]\n",
      "loss: 0.360557 [38400/60000]\n",
      "loss: 0.517665 [44800/60000]\n",
      "loss: 0.490578 [51200/60000]\n",
      "loss: 0.354437 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.006416 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: 0.228825 [    0/60000]\n",
      "loss: 0.391102 [ 6400/60000]\n",
      "loss: 0.247550 [12800/60000]\n",
      "loss: 0.425274 [19200/60000]\n",
      "loss: 0.322577 [25600/60000]\n",
      "loss: 0.361247 [32000/60000]\n",
      "loss: 0.359841 [38400/60000]\n",
      "loss: 0.516639 [44800/60000]\n",
      "loss: 0.489538 [51200/60000]\n",
      "loss: 0.354079 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.006408 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: 0.228453 [    0/60000]\n",
      "loss: 0.390289 [ 6400/60000]\n",
      "loss: 0.247182 [12800/60000]\n",
      "loss: 0.424323 [19200/60000]\n",
      "loss: 0.321935 [25600/60000]\n",
      "loss: 0.360571 [32000/60000]\n",
      "loss: 0.359088 [38400/60000]\n",
      "loss: 0.515613 [44800/60000]\n",
      "loss: 0.488504 [51200/60000]\n",
      "loss: 0.353640 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.4%, Avg loss: 0.006400 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: 0.228135 [    0/60000]\n",
      "loss: 0.389429 [ 6400/60000]\n",
      "loss: 0.246809 [12800/60000]\n",
      "loss: 0.423352 [19200/60000]\n",
      "loss: 0.321326 [25600/60000]\n",
      "loss: 0.359878 [32000/60000]\n",
      "loss: 0.358292 [38400/60000]\n",
      "loss: 0.514531 [44800/60000]\n",
      "loss: 0.487519 [51200/60000]\n",
      "loss: 0.353230 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.006392 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: 0.227788 [    0/60000]\n",
      "loss: 0.388544 [ 6400/60000]\n",
      "loss: 0.246445 [12800/60000]\n",
      "loss: 0.422440 [19200/60000]\n",
      "loss: 0.320735 [25600/60000]\n",
      "loss: 0.359244 [32000/60000]\n",
      "loss: 0.357551 [38400/60000]\n",
      "loss: 0.513523 [44800/60000]\n",
      "loss: 0.486514 [51200/60000]\n",
      "loss: 0.352816 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.006384 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: 0.227449 [    0/60000]\n",
      "loss: 0.387668 [ 6400/60000]\n",
      "loss: 0.246065 [12800/60000]\n",
      "loss: 0.421532 [19200/60000]\n",
      "loss: 0.320169 [25600/60000]\n",
      "loss: 0.358578 [32000/60000]\n",
      "loss: 0.356791 [38400/60000]\n",
      "loss: 0.512515 [44800/60000]\n",
      "loss: 0.485564 [51200/60000]\n",
      "loss: 0.352462 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.006376 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: 0.227027 [    0/60000]\n",
      "loss: 0.386935 [ 6400/60000]\n",
      "loss: 0.245728 [12800/60000]\n",
      "loss: 0.420560 [19200/60000]\n",
      "loss: 0.319606 [25600/60000]\n",
      "loss: 0.357938 [32000/60000]\n",
      "loss: 0.356053 [38400/60000]\n",
      "loss: 0.511477 [44800/60000]\n",
      "loss: 0.484611 [51200/60000]\n",
      "loss: 0.352091 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.006369 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: 0.226701 [    0/60000]\n",
      "loss: 0.386077 [ 6400/60000]\n",
      "loss: 0.245405 [12800/60000]\n",
      "loss: 0.419558 [19200/60000]\n",
      "loss: 0.319078 [25600/60000]\n",
      "loss: 0.357222 [32000/60000]\n",
      "loss: 0.355262 [38400/60000]\n",
      "loss: 0.510543 [44800/60000]\n",
      "loss: 0.483707 [51200/60000]\n",
      "loss: 0.351754 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.5%, Avg loss: 0.006361 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: 0.226300 [    0/60000]\n",
      "loss: 0.385206 [ 6400/60000]\n",
      "loss: 0.245030 [12800/60000]\n",
      "loss: 0.418607 [19200/60000]\n",
      "loss: 0.318496 [25600/60000]\n",
      "loss: 0.356561 [32000/60000]\n",
      "loss: 0.354471 [38400/60000]\n",
      "loss: 0.509595 [44800/60000]\n",
      "loss: 0.482833 [51200/60000]\n",
      "loss: 0.351460 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.006353 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: 0.225932 [    0/60000]\n",
      "loss: 0.384342 [ 6400/60000]\n",
      "loss: 0.244652 [12800/60000]\n",
      "loss: 0.417690 [19200/60000]\n",
      "loss: 0.317995 [25600/60000]\n",
      "loss: 0.355889 [32000/60000]\n",
      "loss: 0.353717 [38400/60000]\n",
      "loss: 0.508596 [44800/60000]\n",
      "loss: 0.481890 [51200/60000]\n",
      "loss: 0.351164 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.006346 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: 0.225569 [    0/60000]\n",
      "loss: 0.383594 [ 6400/60000]\n",
      "loss: 0.244347 [12800/60000]\n",
      "loss: 0.416738 [19200/60000]\n",
      "loss: 0.317504 [25600/60000]\n",
      "loss: 0.355214 [32000/60000]\n",
      "loss: 0.353016 [38400/60000]\n",
      "loss: 0.507665 [44800/60000]\n",
      "loss: 0.481026 [51200/60000]\n",
      "loss: 0.350859 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.6%, Avg loss: 0.006338 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: 0.225224 [    0/60000]\n",
      "loss: 0.382801 [ 6400/60000]\n",
      "loss: 0.243983 [12800/60000]\n",
      "loss: 0.415822 [19200/60000]\n",
      "loss: 0.316975 [25600/60000]\n",
      "loss: 0.354611 [32000/60000]\n",
      "loss: 0.352342 [38400/60000]\n",
      "loss: 0.506753 [44800/60000]\n",
      "loss: 0.480068 [51200/60000]\n",
      "loss: 0.350536 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.006331 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: 0.224925 [    0/60000]\n",
      "loss: 0.382023 [ 6400/60000]\n",
      "loss: 0.243570 [12800/60000]\n",
      "loss: 0.414914 [19200/60000]\n",
      "loss: 0.316540 [25600/60000]\n",
      "loss: 0.354041 [32000/60000]\n",
      "loss: 0.351699 [38400/60000]\n",
      "loss: 0.505755 [44800/60000]\n",
      "loss: 0.479198 [51200/60000]\n",
      "loss: 0.350161 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.006324 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: 0.224699 [    0/60000]\n",
      "loss: 0.381197 [ 6400/60000]\n",
      "loss: 0.243201 [12800/60000]\n",
      "loss: 0.413953 [19200/60000]\n",
      "loss: 0.316067 [25600/60000]\n",
      "loss: 0.353391 [32000/60000]\n",
      "loss: 0.351003 [38400/60000]\n",
      "loss: 0.504761 [44800/60000]\n",
      "loss: 0.478317 [51200/60000]\n",
      "loss: 0.349733 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.7%, Avg loss: 0.006316 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: 0.224438 [    0/60000]\n",
      "loss: 0.380438 [ 6400/60000]\n",
      "loss: 0.242810 [12800/60000]\n",
      "loss: 0.413018 [19200/60000]\n",
      "loss: 0.315629 [25600/60000]\n",
      "loss: 0.352858 [32000/60000]\n",
      "loss: 0.350337 [38400/60000]\n",
      "loss: 0.503786 [44800/60000]\n",
      "loss: 0.477458 [51200/60000]\n",
      "loss: 0.349330 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.006309 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: 0.224236 [    0/60000]\n",
      "loss: 0.379651 [ 6400/60000]\n",
      "loss: 0.242456 [12800/60000]\n",
      "loss: 0.412073 [19200/60000]\n",
      "loss: 0.315125 [25600/60000]\n",
      "loss: 0.352319 [32000/60000]\n",
      "loss: 0.349657 [38400/60000]\n",
      "loss: 0.502876 [44800/60000]\n",
      "loss: 0.476556 [51200/60000]\n",
      "loss: 0.348908 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.006302 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: 0.223938 [    0/60000]\n",
      "loss: 0.378931 [ 6400/60000]\n",
      "loss: 0.242122 [12800/60000]\n",
      "loss: 0.411190 [19200/60000]\n",
      "loss: 0.314638 [25600/60000]\n",
      "loss: 0.351837 [32000/60000]\n",
      "loss: 0.348925 [38400/60000]\n",
      "loss: 0.502071 [44800/60000]\n",
      "loss: 0.475626 [51200/60000]\n",
      "loss: 0.348544 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.006294 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: 0.223556 [    0/60000]\n",
      "loss: 0.378159 [ 6400/60000]\n",
      "loss: 0.241787 [12800/60000]\n",
      "loss: 0.410237 [19200/60000]\n",
      "loss: 0.314240 [25600/60000]\n",
      "loss: 0.351417 [32000/60000]\n",
      "loss: 0.348321 [38400/60000]\n",
      "loss: 0.501191 [44800/60000]\n",
      "loss: 0.474769 [51200/60000]\n",
      "loss: 0.348334 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.8%, Avg loss: 0.006288 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: 0.223266 [    0/60000]\n",
      "loss: 0.377349 [ 6400/60000]\n",
      "loss: 0.241476 [12800/60000]\n",
      "loss: 0.409321 [19200/60000]\n",
      "loss: 0.313860 [25600/60000]\n",
      "loss: 0.350868 [32000/60000]\n",
      "loss: 0.347756 [38400/60000]\n",
      "loss: 0.500238 [44800/60000]\n",
      "loss: 0.473877 [51200/60000]\n",
      "loss: 0.348017 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.006281 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: 0.222969 [    0/60000]\n",
      "loss: 0.376535 [ 6400/60000]\n",
      "loss: 0.241181 [12800/60000]\n",
      "loss: 0.408403 [19200/60000]\n",
      "loss: 0.313518 [25600/60000]\n",
      "loss: 0.350356 [32000/60000]\n",
      "loss: 0.347140 [38400/60000]\n",
      "loss: 0.499279 [44800/60000]\n",
      "loss: 0.473050 [51200/60000]\n",
      "loss: 0.347674 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.006274 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: 0.222688 [    0/60000]\n",
      "loss: 0.375711 [ 6400/60000]\n",
      "loss: 0.240910 [12800/60000]\n",
      "loss: 0.407527 [19200/60000]\n",
      "loss: 0.313203 [25600/60000]\n",
      "loss: 0.349771 [32000/60000]\n",
      "loss: 0.346453 [38400/60000]\n",
      "loss: 0.498295 [44800/60000]\n",
      "loss: 0.472164 [51200/60000]\n",
      "loss: 0.347310 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.006267 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: 0.222385 [    0/60000]\n",
      "loss: 0.374880 [ 6400/60000]\n",
      "loss: 0.240587 [12800/60000]\n",
      "loss: 0.406661 [19200/60000]\n",
      "loss: 0.312829 [25600/60000]\n",
      "loss: 0.349247 [32000/60000]\n",
      "loss: 0.345798 [38400/60000]\n",
      "loss: 0.497377 [44800/60000]\n",
      "loss: 0.471237 [51200/60000]\n",
      "loss: 0.347013 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.006261 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: 0.222107 [    0/60000]\n",
      "loss: 0.374152 [ 6400/60000]\n",
      "loss: 0.240275 [12800/60000]\n",
      "loss: 0.405767 [19200/60000]\n",
      "loss: 0.312398 [25600/60000]\n",
      "loss: 0.348727 [32000/60000]\n",
      "loss: 0.345217 [38400/60000]\n",
      "loss: 0.496448 [44800/60000]\n",
      "loss: 0.470274 [51200/60000]\n",
      "loss: 0.346640 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.006254 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: 0.221786 [    0/60000]\n",
      "loss: 0.373399 [ 6400/60000]\n",
      "loss: 0.239916 [12800/60000]\n",
      "loss: 0.404893 [19200/60000]\n",
      "loss: 0.312027 [25600/60000]\n",
      "loss: 0.348181 [32000/60000]\n",
      "loss: 0.344566 [38400/60000]\n",
      "loss: 0.495505 [44800/60000]\n",
      "loss: 0.469356 [51200/60000]\n",
      "loss: 0.346289 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.006247 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: 0.221538 [    0/60000]\n",
      "loss: 0.372693 [ 6400/60000]\n",
      "loss: 0.239593 [12800/60000]\n",
      "loss: 0.404043 [19200/60000]\n",
      "loss: 0.311582 [25600/60000]\n",
      "loss: 0.347707 [32000/60000]\n",
      "loss: 0.343921 [38400/60000]\n",
      "loss: 0.494552 [44800/60000]\n",
      "loss: 0.468467 [51200/60000]\n",
      "loss: 0.345905 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 85.9%, Avg loss: 0.006241 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: 0.221205 [    0/60000]\n",
      "loss: 0.371986 [ 6400/60000]\n",
      "loss: 0.239253 [12800/60000]\n",
      "loss: 0.403162 [19200/60000]\n",
      "loss: 0.311258 [25600/60000]\n",
      "loss: 0.347201 [32000/60000]\n",
      "loss: 0.343379 [38400/60000]\n",
      "loss: 0.493587 [44800/60000]\n",
      "loss: 0.467594 [51200/60000]\n",
      "loss: 0.345535 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.006234 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: 0.220921 [    0/60000]\n",
      "loss: 0.371266 [ 6400/60000]\n",
      "loss: 0.238939 [12800/60000]\n",
      "loss: 0.402294 [19200/60000]\n",
      "loss: 0.310923 [25600/60000]\n",
      "loss: 0.346712 [32000/60000]\n",
      "loss: 0.342767 [38400/60000]\n",
      "loss: 0.492679 [44800/60000]\n",
      "loss: 0.466763 [51200/60000]\n",
      "loss: 0.345172 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.006228 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: 0.220662 [    0/60000]\n",
      "loss: 0.370558 [ 6400/60000]\n",
      "loss: 0.238653 [12800/60000]\n",
      "loss: 0.401436 [19200/60000]\n",
      "loss: 0.310567 [25600/60000]\n",
      "loss: 0.346206 [32000/60000]\n",
      "loss: 0.342151 [38400/60000]\n",
      "loss: 0.491743 [44800/60000]\n",
      "loss: 0.465866 [51200/60000]\n",
      "loss: 0.344818 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.0%, Avg loss: 0.006221 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: 0.220401 [    0/60000]\n",
      "loss: 0.369808 [ 6400/60000]\n",
      "loss: 0.238372 [12800/60000]\n",
      "loss: 0.400586 [19200/60000]\n",
      "loss: 0.310246 [25600/60000]\n",
      "loss: 0.345669 [32000/60000]\n",
      "loss: 0.341634 [38400/60000]\n",
      "loss: 0.490746 [44800/60000]\n",
      "loss: 0.465051 [51200/60000]\n",
      "loss: 0.344450 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.006215 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: 0.220107 [    0/60000]\n",
      "loss: 0.369154 [ 6400/60000]\n",
      "loss: 0.238060 [12800/60000]\n",
      "loss: 0.399846 [19200/60000]\n",
      "loss: 0.309901 [25600/60000]\n",
      "loss: 0.345232 [32000/60000]\n",
      "loss: 0.341130 [38400/60000]\n",
      "loss: 0.489867 [44800/60000]\n",
      "loss: 0.464257 [51200/60000]\n",
      "loss: 0.344071 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.006209 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: 0.219836 [    0/60000]\n",
      "loss: 0.368459 [ 6400/60000]\n",
      "loss: 0.237741 [12800/60000]\n",
      "loss: 0.399108 [19200/60000]\n",
      "loss: 0.309550 [25600/60000]\n",
      "loss: 0.344721 [32000/60000]\n",
      "loss: 0.340647 [38400/60000]\n",
      "loss: 0.488944 [44800/60000]\n",
      "loss: 0.463486 [51200/60000]\n",
      "loss: 0.343612 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.006202 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: 0.219617 [    0/60000]\n",
      "loss: 0.367766 [ 6400/60000]\n",
      "loss: 0.237467 [12800/60000]\n",
      "loss: 0.398325 [19200/60000]\n",
      "loss: 0.309194 [25600/60000]\n",
      "loss: 0.344213 [32000/60000]\n",
      "loss: 0.340177 [38400/60000]\n",
      "loss: 0.488026 [44800/60000]\n",
      "loss: 0.462755 [51200/60000]\n",
      "loss: 0.343153 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.006196 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: 0.219387 [    0/60000]\n",
      "loss: 0.367017 [ 6400/60000]\n",
      "loss: 0.237256 [12800/60000]\n",
      "loss: 0.397476 [19200/60000]\n",
      "loss: 0.308903 [25600/60000]\n",
      "loss: 0.343711 [32000/60000]\n",
      "loss: 0.339610 [38400/60000]\n",
      "loss: 0.487106 [44800/60000]\n",
      "loss: 0.461938 [51200/60000]\n",
      "loss: 0.342682 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.006190 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: 0.219099 [    0/60000]\n",
      "loss: 0.366376 [ 6400/60000]\n",
      "loss: 0.237019 [12800/60000]\n",
      "loss: 0.396686 [19200/60000]\n",
      "loss: 0.308532 [25600/60000]\n",
      "loss: 0.343214 [32000/60000]\n",
      "loss: 0.339168 [38400/60000]\n",
      "loss: 0.486105 [44800/60000]\n",
      "loss: 0.461131 [51200/60000]\n",
      "loss: 0.342203 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.006184 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: 0.218820 [    0/60000]\n",
      "loss: 0.365733 [ 6400/60000]\n",
      "loss: 0.236764 [12800/60000]\n",
      "loss: 0.395923 [19200/60000]\n",
      "loss: 0.308150 [25600/60000]\n",
      "loss: 0.342756 [32000/60000]\n",
      "loss: 0.338643 [38400/60000]\n",
      "loss: 0.485195 [44800/60000]\n",
      "loss: 0.460311 [51200/60000]\n",
      "loss: 0.341762 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.006178 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: 0.218546 [    0/60000]\n",
      "loss: 0.365112 [ 6400/60000]\n",
      "loss: 0.236501 [12800/60000]\n",
      "loss: 0.395221 [19200/60000]\n",
      "loss: 0.307764 [25600/60000]\n",
      "loss: 0.342322 [32000/60000]\n",
      "loss: 0.338109 [38400/60000]\n",
      "loss: 0.484253 [44800/60000]\n",
      "loss: 0.459590 [51200/60000]\n",
      "loss: 0.341298 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.1%, Avg loss: 0.006172 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: 0.218305 [    0/60000]\n",
      "loss: 0.364463 [ 6400/60000]\n",
      "loss: 0.236299 [12800/60000]\n",
      "loss: 0.394396 [19200/60000]\n",
      "loss: 0.307401 [25600/60000]\n",
      "loss: 0.341848 [32000/60000]\n",
      "loss: 0.337573 [38400/60000]\n",
      "loss: 0.483291 [44800/60000]\n",
      "loss: 0.458864 [51200/60000]\n",
      "loss: 0.340894 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.006166 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: 0.217974 [    0/60000]\n",
      "loss: 0.363871 [ 6400/60000]\n",
      "loss: 0.235962 [12800/60000]\n",
      "loss: 0.393661 [19200/60000]\n",
      "loss: 0.306998 [25600/60000]\n",
      "loss: 0.341446 [32000/60000]\n",
      "loss: 0.337166 [38400/60000]\n",
      "loss: 0.482421 [44800/60000]\n",
      "loss: 0.458074 [51200/60000]\n",
      "loss: 0.340478 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.006160 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: 0.217719 [    0/60000]\n",
      "loss: 0.363228 [ 6400/60000]\n",
      "loss: 0.235702 [12800/60000]\n",
      "loss: 0.392927 [19200/60000]\n",
      "loss: 0.306668 [25600/60000]\n",
      "loss: 0.340949 [32000/60000]\n",
      "loss: 0.336700 [38400/60000]\n",
      "loss: 0.481461 [44800/60000]\n",
      "loss: 0.457346 [51200/60000]\n",
      "loss: 0.340002 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.006154 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: 0.217432 [    0/60000]\n",
      "loss: 0.362631 [ 6400/60000]\n",
      "loss: 0.235435 [12800/60000]\n",
      "loss: 0.392195 [19200/60000]\n",
      "loss: 0.306307 [25600/60000]\n",
      "loss: 0.340459 [32000/60000]\n",
      "loss: 0.336267 [38400/60000]\n",
      "loss: 0.480488 [44800/60000]\n",
      "loss: 0.456643 [51200/60000]\n",
      "loss: 0.339535 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.006148 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: 0.217180 [    0/60000]\n",
      "loss: 0.362015 [ 6400/60000]\n",
      "loss: 0.235070 [12800/60000]\n",
      "loss: 0.391448 [19200/60000]\n",
      "loss: 0.305986 [25600/60000]\n",
      "loss: 0.340039 [32000/60000]\n",
      "loss: 0.335758 [38400/60000]\n",
      "loss: 0.479579 [44800/60000]\n",
      "loss: 0.455951 [51200/60000]\n",
      "loss: 0.339020 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.006142 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: 0.216914 [    0/60000]\n",
      "loss: 0.361396 [ 6400/60000]\n",
      "loss: 0.234797 [12800/60000]\n",
      "loss: 0.390680 [19200/60000]\n",
      "loss: 0.305653 [25600/60000]\n",
      "loss: 0.339596 [32000/60000]\n",
      "loss: 0.335269 [38400/60000]\n",
      "loss: 0.478716 [44800/60000]\n",
      "loss: 0.455343 [51200/60000]\n",
      "loss: 0.338466 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.2%, Avg loss: 0.006136 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: 0.216638 [    0/60000]\n",
      "loss: 0.360799 [ 6400/60000]\n",
      "loss: 0.234484 [12800/60000]\n",
      "loss: 0.389922 [19200/60000]\n",
      "loss: 0.305280 [25600/60000]\n",
      "loss: 0.339131 [32000/60000]\n",
      "loss: 0.334781 [38400/60000]\n",
      "loss: 0.477770 [44800/60000]\n",
      "loss: 0.454562 [51200/60000]\n",
      "loss: 0.338106 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.006130 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: 0.216258 [    0/60000]\n",
      "loss: 0.360187 [ 6400/60000]\n",
      "loss: 0.234183 [12800/60000]\n",
      "loss: 0.389159 [19200/60000]\n",
      "loss: 0.305044 [25600/60000]\n",
      "loss: 0.338696 [32000/60000]\n",
      "loss: 0.334313 [38400/60000]\n",
      "loss: 0.476919 [44800/60000]\n",
      "loss: 0.453817 [51200/60000]\n",
      "loss: 0.337661 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.006124 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: 0.215999 [    0/60000]\n",
      "loss: 0.359678 [ 6400/60000]\n",
      "loss: 0.233882 [12800/60000]\n",
      "loss: 0.388467 [19200/60000]\n",
      "loss: 0.304787 [25600/60000]\n",
      "loss: 0.338281 [32000/60000]\n",
      "loss: 0.333906 [38400/60000]\n",
      "loss: 0.476093 [44800/60000]\n",
      "loss: 0.453135 [51200/60000]\n",
      "loss: 0.337284 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.006119 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: 0.215825 [    0/60000]\n",
      "loss: 0.359127 [ 6400/60000]\n",
      "loss: 0.233512 [12800/60000]\n",
      "loss: 0.387721 [19200/60000]\n",
      "loss: 0.304578 [25600/60000]\n",
      "loss: 0.337915 [32000/60000]\n",
      "loss: 0.333523 [38400/60000]\n",
      "loss: 0.475309 [44800/60000]\n",
      "loss: 0.452418 [51200/60000]\n",
      "loss: 0.336851 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.3%, Avg loss: 0.006113 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: 0.215630 [    0/60000]\n",
      "loss: 0.358573 [ 6400/60000]\n",
      "loss: 0.233127 [12800/60000]\n",
      "loss: 0.386985 [19200/60000]\n",
      "loss: 0.304374 [25600/60000]\n",
      "loss: 0.337475 [32000/60000]\n",
      "loss: 0.333059 [38400/60000]\n",
      "loss: 0.474491 [44800/60000]\n",
      "loss: 0.451638 [51200/60000]\n",
      "loss: 0.336528 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.006107 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: 0.215413 [    0/60000]\n",
      "loss: 0.358004 [ 6400/60000]\n",
      "loss: 0.232796 [12800/60000]\n",
      "loss: 0.386334 [19200/60000]\n",
      "loss: 0.304127 [25600/60000]\n",
      "loss: 0.337089 [32000/60000]\n",
      "loss: 0.332585 [38400/60000]\n",
      "loss: 0.473674 [44800/60000]\n",
      "loss: 0.450859 [51200/60000]\n",
      "loss: 0.336252 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.006102 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: 0.215111 [    0/60000]\n",
      "loss: 0.357440 [ 6400/60000]\n",
      "loss: 0.232488 [12800/60000]\n",
      "loss: 0.385633 [19200/60000]\n",
      "loss: 0.303875 [25600/60000]\n",
      "loss: 0.336684 [32000/60000]\n",
      "loss: 0.332085 [38400/60000]\n",
      "loss: 0.472898 [44800/60000]\n",
      "loss: 0.450069 [51200/60000]\n",
      "loss: 0.336017 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.006096 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: 0.214820 [    0/60000]\n",
      "loss: 0.356847 [ 6400/60000]\n",
      "loss: 0.232223 [12800/60000]\n",
      "loss: 0.384973 [19200/60000]\n",
      "loss: 0.303578 [25600/60000]\n",
      "loss: 0.336269 [32000/60000]\n",
      "loss: 0.331651 [38400/60000]\n",
      "loss: 0.472120 [44800/60000]\n",
      "loss: 0.449306 [51200/60000]\n",
      "loss: 0.335720 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.006090 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: 0.214565 [    0/60000]\n",
      "loss: 0.356263 [ 6400/60000]\n",
      "loss: 0.231875 [12800/60000]\n",
      "loss: 0.384295 [19200/60000]\n",
      "loss: 0.303304 [25600/60000]\n",
      "loss: 0.335852 [32000/60000]\n",
      "loss: 0.331121 [38400/60000]\n",
      "loss: 0.471348 [44800/60000]\n",
      "loss: 0.448493 [51200/60000]\n",
      "loss: 0.335397 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.4%, Avg loss: 0.006084 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: 0.214277 [    0/60000]\n",
      "loss: 0.355661 [ 6400/60000]\n",
      "loss: 0.231525 [12800/60000]\n",
      "loss: 0.383573 [19200/60000]\n",
      "loss: 0.302995 [25600/60000]\n",
      "loss: 0.335355 [32000/60000]\n",
      "loss: 0.330647 [38400/60000]\n",
      "loss: 0.470553 [44800/60000]\n",
      "loss: 0.447687 [51200/60000]\n",
      "loss: 0.335098 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.006079 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: 0.213998 [    0/60000]\n",
      "loss: 0.355016 [ 6400/60000]\n",
      "loss: 0.231245 [12800/60000]\n",
      "loss: 0.382922 [19200/60000]\n",
      "loss: 0.302653 [25600/60000]\n",
      "loss: 0.334830 [32000/60000]\n",
      "loss: 0.330080 [38400/60000]\n",
      "loss: 0.469825 [44800/60000]\n",
      "loss: 0.446831 [51200/60000]\n",
      "loss: 0.334729 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.006073 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: 0.213770 [    0/60000]\n",
      "loss: 0.354405 [ 6400/60000]\n",
      "loss: 0.230942 [12800/60000]\n",
      "loss: 0.382203 [19200/60000]\n",
      "loss: 0.302299 [25600/60000]\n",
      "loss: 0.334287 [32000/60000]\n",
      "loss: 0.329581 [38400/60000]\n",
      "loss: 0.469114 [44800/60000]\n",
      "loss: 0.445955 [51200/60000]\n",
      "loss: 0.334425 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.006068 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: 0.213533 [    0/60000]\n",
      "loss: 0.353778 [ 6400/60000]\n",
      "loss: 0.230588 [12800/60000]\n",
      "loss: 0.381499 [19200/60000]\n",
      "loss: 0.301946 [25600/60000]\n",
      "loss: 0.333723 [32000/60000]\n",
      "loss: 0.329133 [38400/60000]\n",
      "loss: 0.468296 [44800/60000]\n",
      "loss: 0.445160 [51200/60000]\n",
      "loss: 0.334018 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.006062 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: 0.213302 [    0/60000]\n",
      "loss: 0.353191 [ 6400/60000]\n",
      "loss: 0.230228 [12800/60000]\n",
      "loss: 0.380751 [19200/60000]\n",
      "loss: 0.301621 [25600/60000]\n",
      "loss: 0.333253 [32000/60000]\n",
      "loss: 0.328711 [38400/60000]\n",
      "loss: 0.467503 [44800/60000]\n",
      "loss: 0.444355 [51200/60000]\n",
      "loss: 0.333687 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.006057 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: 0.213063 [    0/60000]\n",
      "loss: 0.352660 [ 6400/60000]\n",
      "loss: 0.229919 [12800/60000]\n",
      "loss: 0.380059 [19200/60000]\n",
      "loss: 0.301218 [25600/60000]\n",
      "loss: 0.332746 [32000/60000]\n",
      "loss: 0.328327 [38400/60000]\n",
      "loss: 0.466693 [44800/60000]\n",
      "loss: 0.443455 [51200/60000]\n",
      "loss: 0.333317 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.006051 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: 0.212812 [    0/60000]\n",
      "loss: 0.352077 [ 6400/60000]\n",
      "loss: 0.229596 [12800/60000]\n",
      "loss: 0.379344 [19200/60000]\n",
      "loss: 0.300904 [25600/60000]\n",
      "loss: 0.332208 [32000/60000]\n",
      "loss: 0.327886 [38400/60000]\n",
      "loss: 0.465853 [44800/60000]\n",
      "loss: 0.442636 [51200/60000]\n",
      "loss: 0.333035 [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 86.5%, Avg loss: 0.006046 \n",
      "\n",
      "Done! Duration: 272.34 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "end = time.time()\n",
    "duration = round(end - start, 2)\n",
    "print(\"Done! Duration:\", duration, 'seconds')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "# save model\n",
    "\n",
    "# torch.save(model.state_dict(), 'models/tutorial_model')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [],
   "source": [
    "# loading models\n",
    "\n",
    "# tmp = NeuralNetwork()\n",
    "# tmp.load_state_dict(torch.load('models/tutorial_model'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}